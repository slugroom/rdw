import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score
from catboost import CatBoostClassifier
from xgboost import XGBClassifier

# 游늷 1. Carregar os datasets
df_veiculos_motoristas = pd.read_csv("veiculos_motoristas.csv")  # Dados dos ve칤culos e motoristas
df_corridas = pd.read_csv("historico_corridas.csv")  # Hist칩rico de corridas

# 游늷 2. Juntar os datasets com base no identificador do motorista
df = df_corridas.merge(df_veiculos_motoristas, on="id_motorista", how="left")

# Remover colunas desnecess치rias (ex: IDs que n칚o ajudam na previs칚o)
df = df.drop(columns=["id_corrida", "nome_motorista"])

# Definir a vari치vel-alvo (1 = vencedor, 0 = n칚o vencedor)
y = df["vencedor"]
X = df.drop(columns=["vencedor"])

# 游늷 3. Pr칠-processamento dos dados

# Identificar colunas categ칩ricas
categorical_cols = X.select_dtypes(include=["object"]).columns.tolist()

# Aplicar Label Encoding para vari치veis categ칩ricas
label_encoders = {}
for col in categorical_cols:
    le = LabelEncoder()
    X[col] = le.fit_transform(X[col])
    label_encoders[col] = le  # Guardar o encoder caso precise inverter depois

# 游늷 4. Dividir os dados em treino e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 游늷 5. Treinar os Modelos

# CatBoost
catboost_model = CatBoostClassifier(iterations=500, learning_rate=0.05, depth=6, verbose=0)
catboost_model.fit(X_train, y_train)

# XGBoost
xgb_model = XGBClassifier(n_estimators=500, learning_rate=0.05, max_depth=6, use_label_encoder=False, eval_metric="logloss")
xgb_model.fit(X_train, y_train)

# 游늷 6. Fazer Previs칫es
catboost_preds = catboost_model.predict(X_test)
xgb_preds = xgb_model.predict(X_test)

# 游늷 7. Avalia칞칚o dos Modelos
catboost_acc = accuracy_score(y_test, catboost_preds)
xgb_acc = accuracy_score(y_test, xgb_preds)

print(f"游끭 Acur치cia CatBoost: {catboost_acc:.4f}")
print(f"游끭 Acur치cia XGBoost: {xgb_acc:.4f}")
